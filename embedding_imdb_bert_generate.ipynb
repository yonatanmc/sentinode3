{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Carga tu dataframe (aquí asumo que el archivo está en formato CSV)\n",
    "df = pd.read_csv(\"imdb_ds_2k_clean.csv\")  # Cambia esto por la ruta a tu archivo\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = df[\"sw_text\"].tolist()  # Extrae la columna de reviews como lista de oraciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializa el tokenizador y modelo BERT\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para generar embeddings de una palabra\n",
    "def get_word_embedding(word):\n",
    "    inputs = tokenizer(word, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    # Promedia los embeddings para los tokens de la palabra\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
    "    # Reduce la dimensión de 768 a 300\n",
    "    embeddings = embeddings[:300] if embeddings.shape[0] > 300 else np.pad(embeddings, (0, 300 - embeddings.shape[0]), 'constant')\n",
    "    return embeddings\n",
    "\n",
    "# Prepara un conjunto único de palabras en todas las reviews\n",
    "unique_words = set()\n",
    "for review in reviews:\n",
    "    words = review.split()\n",
    "    unique_words.update(words)\n",
    "\n",
    "# Abre un archivo para escribir los embeddings\n",
    "with open(\"embedding_imdb2k_bert.txt\", \"w\") as f:\n",
    "    # Escribe el encabezado con el número de palabras y la dimensión\n",
    "    f.write(f\"{len(unique_words)} 300\\n\")\n",
    "    \n",
    "    for word in unique_words:\n",
    "        # Obtén el embedding de la palabra\n",
    "        embedding = get_word_embedding(word)\n",
    "        # Convierte el embedding en una cadena de texto\n",
    "        embedding_str = \" \".join(map(str, embedding))\n",
    "        # Escribe la palabra seguida de su embedding\n",
    "        f.write(f\"{word} {embedding_str}\\n\")\n",
    "\n",
    "print(\"Embeddings guardados en 'word_embeddings.txt'\") #5min\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
